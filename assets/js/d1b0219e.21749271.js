"use strict";(self.webpackChunkorca_website=self.webpackChunkorca_website||[]).push([[2269],{3900:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>t,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var s=a(4848),i=a(8453);const o={id:"research-lambda-container",title:"Using Lambda functions as container research Notes",description:"Research Notes on Containerizing Lambdas"},t=void 0,r={id:"developer/research/research-lambda-container",title:"Using Lambda functions as container research Notes",description:"Research Notes on Containerizing Lambdas",source:"@site/docs/developer/research/research-lambda-container.md",sourceDirName:"developer/research",slug:"/developer/research/research-lambda-container",permalink:"/cumulus-orca/docs/developer/research/research-lambda-container",draft:!1,unlisted:!1,editUrl:"https://github.com/nasa/cumulus-orca/edit/develop/website/docs/developer/research/research-lambda-container.md",tags:[],version:"current",frontMatter:{id:"research-lambda-container",title:"Using Lambda functions as container research Notes",description:"Research Notes on Containerizing Lambdas"},sidebar:"dev_guide",previous:{title:"Research Notes on running integration tests in bamboo CI/CD",permalink:"/cumulus-orca/docs/developer/research/research-bamboo-integration-tests"},next:{title:"Notes on pushing and deploying docker images.",permalink:"/cumulus-orca/docs/developer/research/research-pushing-docker-image"}},c={},l=[{value:"Overview",id:"overview",level:2},{value:"Elastic Container Registry (ECR)",id:"elastic-container-registry-ecr",level:2},{value:"Pros and Cons of using container for lambdas",id:"pros-and-cons-of-using-container-for-lambdas",level:2},{value:"Pros",id:"pros",level:3},{value:"Cons",id:"cons",level:3},{value:"New configuration for lambda container",id:"new-configuration-for-lambda-container",level:2},{value:"Creating a prototype",id:"creating-a-prototype",level:2},{value:"Future directions",id:"future-directions",level:2},{value:"Modifying get_current_archive_list and perform_orca_reconcile",id:"modifying-get_current_archive_list-and-perform_orca_reconcile",level:3},{value:"Recommendation",id:"recommendation",level:4},{value:"References",id:"references",level:5}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",h4:"h4",h5:"h5",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"Lambda functions can now be deployed as container images using Docker instead of zip files. This research webpage discusses how lambda functions can be prototyped as container and its pros and cons."}),"\n",(0,s.jsx)(n.h2,{id:"elastic-container-registry-ecr",children:"Elastic Container Registry (ECR)"}),"\n",(0,s.jsxs)(n.p,{children:["AWS Elastic Container Registry(ECR) is used to store container images for lambdas and is fully managed by AWS. It hosts the images in a highly available and scalable architecture, allowing developers to reliably deploy containers for their applications. See this ",(0,s.jsx)(n.a,{href:"https://aws.amazon.com/ecr/",children:"link"})," for additional information on ECR. Currently, you have to use ECR to store container images for lambdas as it does not support other storage options such as Github, Dockerhub, etc."]}),"\n",(0,s.jsx)(n.h2,{id:"pros-and-cons-of-using-container-for-lambdas",children:"Pros and Cons of using container for lambdas"}),"\n",(0,s.jsx)(n.h3,{id:"pros",children:"Pros"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Defining runtime environment in a container image gives developers more control over their environment compared to what they get with predefined runtimes and zipping dependencies."}),"\n",(0,s.jsx)(n.li,{children:"you can now package and deploy Lambda functions as container images of up to 10 GB in size compared to only 250MB in case of lambda deployment package size."}),"\n",(0,s.jsx)(n.li,{children:"preferable for data-heavy or dependency-heavy applications."}),"\n",(0,s.jsx)(n.li,{children:"The Lambda service provides a variety of base image options with pre-installed runtimes that will be patched and maintained by AWS."}),"\n",(0,s.jsx)(n.li,{children:"Once deployed, containerized lambdas have no additional cost compared to zipped lambdas except the cost of using ECR repository."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"cons",children:"Cons"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Container support requires your Lambda function code point to an ECR Repo URI which means that repo also has to be maintained."}),"\n",(0,s.jsx)(n.li,{children:"need additional work to create the Dockerfile, tag and push the image to ECR repo."}),"\n",(0,s.jsx)(n.li,{children:"Need additional work for deleting older images under the ECR repository."}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"warning",children:(0,s.jsxs)(n.p,{children:["Currently NGAP only allows ",(0,s.jsx)(n.code,{children:"private"})," ECR repository which could bring possible risk and challenges in using a public repository for storing container image for lambdas. More discussion is needed with NGAP on allowing a public repository."]})}),"\n",(0,s.jsx)(n.h2,{id:"new-configuration-for-lambda-container",children:"New configuration for lambda container"}),"\n",(0,s.jsx)(n.p,{children:"There are a few configuration that needs to be added if the lambda is deployed from docker image."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Architecture- This  determines the type of computer processor that Lambda uses to run the function. Lambda provides a choice of instruction set architectures which is either ",(0,s.jsx)(n.code,{children:"arm64"})," or ",(0,s.jsx)(n.code,{children:"x86_64"}),". The ",(0,s.jsx)(n.code,{children:"arm64"})," architecture offer lower cost per Gb/s compared to the other one. Check this ",(0,s.jsx)(n.a,{href:"https://docs.aws.amazon.com/lambda/latest/dg/foundation-arch.html?icmpid=docs_lambda_help",children:"link"})," for additional information."]}),"\n",(0,s.jsxs)(n.li,{children:["Image configuration- These are values that can be used to override the container image settings for ",(0,s.jsx)(n.code,{children:"ENTRYPOINT"}),", ",(0,s.jsx)(n.code,{children:"CMD"}),", ",(0,s.jsx)(n.code,{children:"WORKDIR"})," and ",(0,s.jsx)(n.code,{children:"ENV"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"  ENTRYPOINT \u2013 Specifies the absolute path of the entry point to the application.\n\n  CMD \u2013 Specifies parameters that you want to pass in with ENTRYPOINT.\n\n  WORKDIR \u2013 Specifies the absolute path of the working directory.\n\n  ENV \u2013 Specifies an environment variable for the Lambda function.\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Image URI- The location of the container image to use for your function."}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"creating-a-prototype",children:"Creating a prototype"}),"\n",(0,s.jsx)(n.p,{children:"Creating or updating the function is done by building a Docker image, uploading the new version to ECR and deploying/updating the Lambda function to point to the newly uploaded image using terraform. Docker CLI has been used to build, tag and push the container image to ECR."}),"\n",(0,s.jsx)(n.p,{children:"The steps for prototyping lambda container are as follows:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Create or locate an AWS ECR repository for storing the Docker images."}),"\n",(0,s.jsx)(n.li,{children:"Create the Dockerfile and then build, tag and push the image to the above ECR repository."}),"\n",(0,s.jsx)(n.li,{children:"Update terraform configuration of the lambda function to deploy it as container."}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"warning",children:(0,s.jsxs)(n.p,{children:["Currently NGAP only allows developers to create a ",(0,s.jsx)(n.code,{children:"private"})," ECR repository which was used here to create the prototype. Using a ",(0,s.jsx)(n.code,{children:"public"})," ECR repository will need approval from NGAP first which could bring security concerns."]})}),"\n",(0,s.jsx)(n.p,{children:"Details on creating the prototype are shown below:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Create an ",(0,s.jsx)(n.a,{href:"https://us-west-2.console.aws.amazon.com/ecr/repositories",children:"ECR"})," repository from AWS CLI if needed as shown. Check ",(0,s.jsx)(n.a,{href:"https://docs.aws.amazon.com/AmazonECR/latest/userguide/getting-started-cli.html#cli-create-repository",children:"here"})," for additional details on this."]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"aws ecr create-repository \\\n    --repository-name <YOUR_REPOSITORY_NAME>\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsxs)(n.li,{children:["Create a project directory. Under that directory, add  your script (",(0,s.jsx)(n.code,{children:"test.py"})," in this case) and ",(0,s.jsx)(n.code,{children:"requirements.txt"}),"to install any dependencies. Then create a ",(0,s.jsx)(n.code,{children:"Dockerfile"})," that creates the image."]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:"You should use the AWS lambda base image specific to the language you are using to write the lambda function."})}),"\n",(0,s.jsxs)(n.p,{children:["An example of a Dockerfile used for prototying a lambda having ",(0,s.jsx)(n.code,{children:"test.py"})," file is shown below."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'FROM public.ecr.aws/lambda/python:3.8\n\n# Copy function code\nCOPY test.py ${LAMBDA_TASK_ROOT}\n\n# Install the function\'s dependencies using file requirements.txt\n# from your project folder.\n\nCOPY requirements.txt  .\nRUN  pip3 install -r requirements.txt --target "${LAMBDA_TASK_ROOT}"\n\n# Set the CMD to your handler (could also be done as a parameter override outside of the Dockerfile)\nCMD [ "test.lambda_handler" ]\n\n'})}),"\n",(0,s.jsxs)(n.ol,{start:"3",children:["\n",(0,s.jsxs)(n.li,{children:["The next steps are to build, tag and push the image to the ECR repo. You can build a new image named ",(0,s.jsx)(n.code,{children:"prototype-lambda-image"})," in this case using:"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker build -t prototype-lambda-image .\n"})}),"\n",(0,s.jsx)(n.p,{children:"Once build is successful, tag the image"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker tag prototype-lambda-image:<IMAGE_TAG> <YOUR_ECR_REPO_URI>:<IMAGE_TAG>\n"})}),"\n",(0,s.jsx)(n.p,{children:"Next, login to the ECR repo using:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"aws ecr get-login-password --region <YOUR_REGION> | docker login --username AWS --password-stdin <YOUR_AWS_ACCOUNT_ID>.dkr.ecr.<YOUR_REGION>.amazonaws.com\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Check this ",(0,s.jsx)(n.a,{href:"https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-push-ecr-image.html",children:"link"})," for additional information on pushing image to ECR using Docker CLI."]}),"\n",(0,s.jsx)(n.p,{children:"Finally, push the image to ECR using:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker push <YOUR_ECR_REPO_URI>:<IMAGE_TAG>\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"4",children:["\n",(0,s.jsx)(n.li,{children:"The next step is to deploy the lambda using terraform. Use the following example code to deploy the lambda container:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-terraform",children:'\nresource "aws_lambda_function" "prototype_lambda" {\n  image_uri     = "<YOUR_ECR_REPO_URI>:<IMAGE_TAG>"  # repo and tag\n  package_type  = "Image"\n  function_name = "prototype-lambda"\n  role          = "<YOUR_IAM_ROLE_ARN>"\n  image_config {\n    command = ["test.lambda_handler"]\n  }\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Using the steps above, a prototype has been created in NGAP AWS sandbox account which can be seen under the lambda function console. The lambda function is named as ",(0,s.jsx)(n.code,{children:"prototype-lambda-container"})," and uses the ",(0,s.jsx)(n.code,{children:"test:latest"})," private ECR repo image."]}),"\n",(0,s.jsx)(n.h2,{id:"future-directions",children:"Future directions"}),"\n",(0,s.jsx)(n.p,{children:"Currently, the only option to store the Docker image for lambda containers is AWS ECR repository. Github package could be an option to store the image but in order to deploy the lambda, the image has to be stored into an ECR."}),"\n",(0,s.jsx)(n.p,{children:"The above example Dockerfile does not follow best practices. See example in section on Fargate."}),"\n",(0,s.jsx)(n.p,{children:"A few possible discussion items:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Discuss with NGAP team if the docker images can be stored in a public ECR repo."}),"\n",(0,s.jsx)(n.li,{children:"If github packages are supported to store and deploy the lambda, then we have to contact NASA github admins to enable this feature in our repository."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Based on this research, it looks like using lambda as containers is possible when using a private ECR to store the image which is not ideal in our case. There are some concerns which include:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Discussing with NGAP on allowing to store container images on a public ECR repository. If that is not possible, another option is to have an ECR setup for the end user via terraform and build images. This will require additional work."}),"\n",(0,s.jsx)(n.li,{children:"If github package is used to store the image, deploying lambda as container will be an issue since the terraform only supports deploying the image from ECR. Moreover, this feature for the github repository has to be approved by NASA Github admins."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["If the above issues are solved, then implementing lambda as container is recommended. One way to use private ECR repo is to use a script or terraform code if possible that will create the ECR repo and then build, tag and push the container image to that repo. One that is done, update the terraform lambda modules and deploy the lambda. An additional ",(0,s.jsx)(n.a,{href:"https://bugs.earthdata.nasa.gov/browse/ORCA-375",children:"card"})," has been created to look into this way."]}),"\n",(0,s.jsx)(n.h3,{id:"modifying-get_current_archive_list-and-perform_orca_reconcile",children:"Modifying get_current_archive_list and perform_orca_reconcile"}),"\n",(0,s.jsx)(n.p,{children:"The Orca Internal Reconciliation workflow lambdas require an alternative approach."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The maximum time limit for lambdas is 15 minutes. These lambdas may take a significant amount of time, and should not be subject to this limitation."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Code changes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Merge ",(0,s.jsx)(n.code,{children:"get_current_archive_list"})," and ",(0,s.jsx)(n.code,{children:"perform_orca_reconcile"})," into one codebase."]}),"\n",(0,s.jsx)(n.li,{children:"Wrap functionality in a loop that will process the internal-report queue until no entries remain."}),"\n",(0,s.jsxs)(n.li,{children:["Since ECS does not support timeout, create an overarching timing mechanic that exits if an infinite loop occurs while processing a queue entry.","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Alternatively, a side-program could manually stop the task if it exceeds its' time limit."}),"\n",(0,s.jsx)(n.li,{children:"Remember that in addition to processing time, Aurora Serverless can take up to 5 minutes to spin up."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Raise the internal-report queue's ",(0,s.jsx)(n.code,{children:"visibility_timeout_seconds"})," to the expected timeout."]}),"\n",(0,s.jsx)(n.li,{children:"Environment variables can be passed in at task definition, or when the task is run. The former should be sufficient."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Use an alternative Dockerfile. The example below packages two code files into a lightweight python container with a ",(0,s.jsx)(n.code,{children:"CMD"})," to run the main file."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'# Build Stage - Here we can bring dev libraries and compile the wheels for the python libs\n# =============================================================================\nFROM python:3.8-slim as builder\n\nWORKDIR /app\n\nENV PYTHONDONTWRITEBYTECODE 1\nENV PYTHONUNBUFFERED 1\n\n# Install the function\'s dependencies using file requirements.txt\n# from your project folder.\nCOPY requirements.txt  .\nRUN pip wheel --no-cache-dir --no-deps --wheel-dir /app/wheels -r requirements.txt\n\n# Run Stage - Contains everything needed to run code with entry point\n# ===================================================================\nFROM python:3.8-slim\n\n# CREATE Non-Privileged User\nRUN mkdir -p /app \\\n    && groupadd -r appuser \\\n    && useradd -r -s /bin/false -g appuser appuser \\\n    && chown -R appuser:appuser /app\n\n# Copy compiled wheels and install the requirements\nCOPY --from=builder /app/wheels /wheels\nRUN pip install --no-cache /wheels/*\n\n# Set the work directory for our application\nWORKDIR /app\n\n# Copy function code\nCOPY main.py main.py\nCOPY sqs_library.py sqs_library.py\n\n# Set the User that the app will run as\nUSER appuser\n\n# Set the entry point for the container\nENTRYPOINT ["python", "main.py"]\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Follow prior instructions up to the Terraform deployment. Use the following Terraform instead of the previous example."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-terraform",children:'data "aws_iam_policy_document" "sqs_task_policy_document" {\n  statement {\n    actions   = ["sts:AssumeRole"]\n    resources = ["*"]\n  }\n  statement {\n    actions = [\n      "sqs:ReceiveMessage",\n      "sqs:SendMessage",\n      "sqs:DeleteMessage",\n      "sqs:GetQueueAttributes"\n    ]\n    resources = ["*"]\n  }\n}\n\ndata "aws_iam_policy_document" "assume_ecs_tasks_role_policy_document" {\n  statement {\n    principals {\n      type        = "Service"\n      identifiers = ["ecs-tasks.amazonaws.com"]\n    }\n    actions = ["sts:AssumeRole"]\n  }\n}\n\n# IAM role that tasks can use to make API requests to authorized AWS services.\nresource "aws_iam_role" "orca_ecs_tasks_role" {\n  name                 = "${var.prefix}_orca_ecs_tasks_role"\n  assume_role_policy   = data.aws_iam_policy_document.assume_ecs_tasks_role_policy_document.json\n  permissions_boundary = var.permissions_boundary_arn\n  tags                 = var.tags\n}\n\nresource "aws_iam_role_policy" "sqs_task_role_policy" {\n  name   = "${var.prefix}_orca_sqs_task_role_policy"\n  role   = aws_iam_role.orca_ecs_tasks_role.id\n  policy = data.aws_iam_policy_document.sqs_task_policy_document.json\n}\n\n# This role is required by tasks to pull container images and publish container logs to Amazon CloudWatch on your behalf.\nresource "aws_iam_role" "orca_ecs_task_execution_role" {\n  name                 = "${var.prefix}_orca_ecs_task_execution_role"\n  assume_role_policy   = data.aws_iam_policy_document.assume_ecs_tasks_role_policy_document.json\n  permissions_boundary = var.permissions_boundary_arn\n  tags                 = var.tags\n}\n\n\nresource "aws_iam_role_policy_attachment" "ecs_role_policy" {\n  role       = aws_iam_role.orca_ecs_task_execution_role.name\n  policy_arn = "arn:aws:iam::aws:policy/AdministratorAccess"\n}\n\nresource "aws_ecs_cluster" "test-cluster" {\n  name = "${var.prefix}_orca_ecs_cluster"\n  capacity_providers = ["FARGATE"]\n  default_capacity_provider_strategy {\n    capacity_provider = "FARGATE"\n    weight            = 100\n  }\n}\n\n# Defines how the image will be run. container_definitions can be replaced by data element.\nresource "aws_ecs_task_definition" "task" {\n  family                   = "${var.prefix}_orca_sqs_task"\n  network_mode             = "awsvpc"\n  requires_compatibilities = ["FARGATE"]\n  cpu                      = "4096"\n  memory                   = "8192"\n  task_role_arn            = aws_iam_role.orca_ecs_tasks_role.arn\n  execution_role_arn       = aws_iam_role.orca_ecs_task_execution_role.arn\n  container_definitions    = <<DEFINITION\n[\n  {\n    "name": "sqs_task_container",\n    "image": "999999999999.dkr.ecr.us-west-2.amazonaws.com/adorn-test-repo:latest",\n    "cpu": 4096,\n    "memory": 256,\n    "networkMode": "awsvpc",\n    "environment": [\n      {\n        "name": "TARGET_QUEUE_URL",\n        "value": "https://sqs.us-west-2.amazonaws.com/999999999999/doctest-orca-internal-report-queue.fifo"\n      }\n    ],\n    "logConfiguration": {\n      "logDriver": "awslogs",\n      "options": {\n        "awslogs-create-group": "true",\n        "awslogs-region": "us-west-2",\n        "awslogs-group": "${var.prefix}_orca_sqs_task",\n        "awslogs-stream-prefix": "ecs"\n      }\n    }\n  }\n]\nDEFINITION\n}\n'})}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["The above example was developed for deploying a simple task that posts to an sqs queue. Names and values should be changed to match new use cases.\nValues such as ",(0,s.jsx)(n.code,{children:"cpu"})," and ",(0,s.jsx)(n.code,{children:"memory"})," should similarly be reevaluated."]})}),"\n",(0,s.jsx)(n.admonition,{type:"warning",children:(0,s.jsx)(n.p,{children:"Applying admin permissions to orca_ecs_task_execution_role is likely overly permissive."})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["The Fargate task can now be run in the ECS cluster.\nThis can be done through ",(0,s.jsx)(n.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs.html#ECS.Client.run_task",children:"boto3"})," or the GUI,\nthough the former is presently untested."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://aws.amazon.com/ecs/pricing/?trk=2f064982-4fad-4e1f-ab75-e1df26258a60&sc_channel=ps&sc_campaign=acquisition&sc_medium=GC-PMM%7CPS-GO%7CBrand%7CAll%7CPA%7CDatabase%7CECS%7CProduct%7CUS%7CEN%7CText%7Cxx%7CSEM%7CPMO22-13405&s_kwcid=AL!4422!3!547620651289!e!!g!!amazon%20ecs%20pricing&ef_id=EAIaIQobChMIsO-ehu2l9wIVCfrICh0gOQ5OEAAYASABEgIZmfD_BwE:G:s&s_kwcid=AL!4422!3!547620651289!e!!g!!amazon%20ecs%20pricing",children:"Pricing"})," only applies to what is used in the moment, and can auto-scale down.","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Minimum compute time is one minute, so this architecture should not be used for small, frequent tasks."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"recommendation",children:"Recommendation"}),"\n",(0,s.jsxs)(n.p,{children:["Recommend use of the above architecture to resolve concerns with timeouts when handling large inventories.\nget_current_archive_list and perform_orca_reconcile can be merged into one codebase, with an overarching loop. ",(0,s.jsx)(n.a,{href:"https://bugs.earthdata.nasa.gov/browse/ORCA-428",children:"https://bugs.earthdata.nasa.gov/browse/ORCA-428"}),"\nThis script can be built into a Docker container and deployed to the result of ",(0,s.jsx)(n.a,{href:"https://bugs.earthdata.nasa.gov/browse/ORCA-375",children:"ECR reserach"}),". ",(0,s.jsx)(n.a,{href:"https://bugs.earthdata.nasa.gov/browse/ORCA-429",children:"https://bugs.earthdata.nasa.gov/browse/ORCA-429"}),"\nThis new script can then be deployed as a task definition in AWS. ",(0,s.jsx)(n.a,{href:"https://bugs.earthdata.nasa.gov/browse/ORCA-432",children:"https://bugs.earthdata.nasa.gov/browse/ORCA-432"}),"\nWe should also create our own ECS cluster to decouple from Cumulus. ",(0,s.jsx)(n.a,{href:"https://bugs.earthdata.nasa.gov/browse/ORCA-433",children:"https://bugs.earthdata.nasa.gov/browse/ORCA-433"}),"\nThe task definition can be run periodically in the ECS cluster to empty the queue of any internal reconciliation jobs. ",(0,s.jsx)(n.a,{href:"https://bugs.earthdata.nasa.gov/browse/ORCA-430",children:"https://bugs.earthdata.nasa.gov/browse/ORCA-430"}),"\nWe can either remove triggering from post_to_queue_and_trigger_step_function or update it to trigger the Fargate task when called.\nIn either case, the old workflow can be removed. ",(0,s.jsx)(n.a,{href:"https://bugs.earthdata.nasa.gov/browse/ORCA-431",children:"https://bugs.earthdata.nasa.gov/browse/ORCA-431"})]}),"\n",(0,s.jsx)(n.h5,{id:"references",children:"References"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support/",children:"https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support/"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://aws.amazon.com/blogs/compute/optimizing-lambda-functions-packaged-as-container-images/",children:"https://aws.amazon.com/blogs/compute/optimizing-lambda-functions-packaged-as-container-images/"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://dashbird.io/blog/deploying-aws-lambda-with-docker/",children:"https://dashbird.io/blog/deploying-aws-lambda-with-docker/"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.aws.amazon.com/lambda/latest/dg/images-create.html",children:"https://docs.aws.amazon.com/lambda/latest/dg/images-create.html"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.aws.amazon.com/lambda/latest/dg/python-image.html",children:"https://docs.aws.amazon.com/lambda/latest/dg/python-image.html"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://acloudguru.com/blog/engineering/packaging-aws-lambda-functions-as-container-images",children:"https://acloudguru.com/blog/engineering/packaging-aws-lambda-functions-as-container-images"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>t,x:()=>r});var s=a(6540);const i={},o=s.createContext(i);function t(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);