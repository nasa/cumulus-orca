"use strict";(self.webpackChunkorca_website=self.webpackChunkorca_website||[]).push([[8493],{8664:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>d,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var n=i(4848),a=i(8453),s=i(6025);const r={id:"research-reconciliation",title:"ORCA Reconciliation",description:"Initial notes, design and ideas related to ORCA Reconciliation with Cumulus"},o=void 0,l={id:"developer/research/research-reconciliation",title:"ORCA Reconciliation",description:"Initial notes, design and ideas related to ORCA Reconciliation with Cumulus",source:"@site/docs/developer/research/research-reconciliation.mdx",sourceDirName:"developer/research",slug:"/developer/research/research-reconciliation",permalink:"/cumulus-orca/docs/developer/research/research-reconciliation",draft:!1,unlisted:!1,editUrl:"https://github.com/nasa/cumulus-orca/edit/develop/website/docs/developer/research/research-reconciliation.mdx",tags:[],version:"current",frontMatter:{id:"research-reconciliation",title:"ORCA Reconciliation",description:"Initial notes, design and ideas related to ORCA Reconciliation with Cumulus"},sidebar:"dev_guide",previous:{title:"API Gateway Research Notes",permalink:"/cumulus-orca/docs/developer/research/research-APIGateway"},next:{title:"Aurora Serverless Research Notes",permalink:"/cumulus-orca/docs/developer/research/research-AuroraServerless"}},d={},c=[{value:"Metadata Needed for Cumulus Comparison",id:"metadata-needed-for-cumulus-comparison",level:2},{value:"Relationship of the Metadata Objects",id:"relationship-of-the-metadata-objects",level:3},{value:"Potential Attributes of the Metadata Objects",id:"potential-attributes-of-the-metadata-objects",level:3},{value:"Provider Metadata Object",id:"provider-metadata-object",level:4},{value:"Collection Metadata Object",id:"collection-metadata-object",level:4},{value:"Granule Metadata Object",id:"granule-metadata-object",level:4},{value:"File Metadata Object",id:"file-metadata-object",level:4},{value:"File Version Object",id:"file-version-object",level:4},{value:"Return Metadata Needed by Cumulus",id:"return-metadata-needed-by-cumulus",level:3},{value:"Potential ORCA Reconciliation Data Reporting Architecture",id:"potential-orca-reconciliation-data-reporting-architecture",level:3},{value:"Populating the metadata",id:"populating-the-metadata",level:2},{value:"Automated Cumulus Ingest Workflow",id:"automated-cumulus-ingest-workflow",level:3},{value:"Boto3 Copy Test",id:"boto3-copy-test",level:4},{value:"Boto3 Get Additional File Information",id:"boto3-get-additional-file-information",level:4},{value:"Boto3 Use Multipart Copy",id:"boto3-use-multipart-copy",level:4},{value:"Manually Run ORCA Ingest Workflows",id:"manually-run-orca-ingest-workflows",level:3},{value:"Back Population of the ORCA Catalog",id:"back-population-of-the-orca-catalog",level:3},{value:"Potential ORCA Catalog Population Architecture",id:"potential-orca-catalog-population-architecture",level:3},{value:"Possible Technologies for Enabling the Work",id:"possible-technologies-for-enabling-the-work",level:2},{value:"API Gateway",id:"api-gateway",level:3},{value:"GraphQL",id:"graphql",level:3},{value:"SQS",id:"sqs",level:3},{value:"AWS PostgreSQL RDS Offerings",id:"aws-postgresql-rds-offerings",level:3},{value:"NodeJS (Knex) / Python (SQLAlchemy)",id:"nodejs-knex--python-sqlalchemy",level:3},{value:"Comparison between ORCA S3 and the ORCA Catalog",id:"comparison-between-orca-s3-and-the-orca-catalog",level:2},{value:"Getting a Listing from AWS S3",id:"getting-a-listing-from-aws-s3",level:3},{value:"Example Using list_objects_v2",id:"example-using-list_objects_v2",level:4},{value:"Potential Internal Reconciliation Architecture",id:"potential-internal-reconciliation-architecture",level:3},{value:"S3 Inventory Report",id:"s3-inventory-report",level:3},{value:"Potential Internal Reporting Database Structure",id:"potential-internal-reporting-database-structure",level:3},{value:"Status Table reconcile_status",id:"status-table-reconcile_status",level:4},{value:"Internal Reconciliation Jobs Table reconcile_job",id:"internal-reconciliation-jobs-table-reconcile_job",level:4},{value:"S3 Inventory Temporary Table reconcile_s3_object",id:"s3-inventory-temporary-table-reconcile_s3_object",level:4},{value:"Internal Reconciliation Reporting Table Orphaned Files reconcile_orphan_report",id:"internal-reconciliation-reporting-table-orphaned-files-reconcile_orphan_report",level:4},{value:"Internal Reconciliation Reporting Table S3 Missing reconcile_phantom_report",id:"internal-reconciliation-reporting-table-s3-missing-reconcile_phantom_report",level:4},{value:"Internal Reconciliation Reporting Table Catalog Missing or Mismatches reconcile_mismatch_report",id:"internal-reconciliation-reporting-table-catalog-missing-or-mismatches-reconcile_mismatch_report",level:4},{value:"Open Questions yet to be answered",id:"open-questions-yet-to-be-answered",level:2},{value:"Additional Artifacts from the Research",id:"additional-artifacts-from-the-research",level:2},{value:"Aqua Data Studio ERD File",id:"aqua-data-studio-erd-file",level:3},{value:"Schema Install SQL Scripts",id:"schema-install-sql-scripts",level:3},{value:"Notes from ORCA schema refinement research",id:"notes-from-orca-schema-refinement-research",level:2},{value:"Refined Granule Metadata Object",id:"refined-granule-metadata-object",level:4},{value:"Refined ERD File &amp; SQL script",id:"refined-erd-file--sql-script",level:3},{value:"Addressing open questions",id:"addressing-open-questions",level:3}];function h(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.p,{children:"As part of enhancing ORCA, a needed feature by the working group is being able to\nreconcile between the ORCA inventory and the Cumulus inventory to determine what\nfile(s) are missing or extra in each catalog. The ORCA team has met with Cumulus\nseveral times to understand current reconciliation patterns. Notes from those\ninterface meetings are available below. In addition, there are several resources\navailable from Cumulus and LZARDS which also has to deal with reconciliation in\na manor similar to ORCA. It is understood that ORCA will provide the data, but\nCumulus will perform the comparison and reporting work to match current reconcile\npatterns."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://wiki.earthdata.nasa.gov/pages/viewpage.action?pageId=195434181",children:"January 28, 2020 Meeting Notes"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://wiki.earthdata.nasa.gov/pages/viewpage.action?pageId=199918974",children:"March 4, 2021 Meeting Notes"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://wiki.earthdata.nasa.gov/pages/viewpage.action?pageId=202806645",children:"March 29, 2021 Meeting Notes"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://wiki.earthdata.nasa.gov/display/CUMULUS/Prototype+LZARDS+reconciliation+reports",children:"LZARDS Prototype Reconciliation Reports"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://nasa.github.io/cumulus-api/#create-reconciliation-report",children:"Cumulus Reconciliation API"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/nasa/cumulus/tree/1e6d63deab3e0cf464b2e8b545258ba1ebb4e05d/lambdas/db-migration/src/migrations",children:"Cumulus table definitions"})}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"metadata-needed-for-cumulus-comparison",children:"Metadata Needed for Cumulus Comparison"}),"\n",(0,n.jsx)(t.p,{children:"The following filters can be applied to a query for determining which files to\nbring back for catalog comparison between the Cumulus inventory and ORCA."}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"providerId"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"List[str]"})}),(0,n.jsx)(t.td,{children:"The unique ID of the provider(s) making the request."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"collectionId"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"List[str]"})}),(0,n.jsx)(t.td,{children:"The unique ID of collection(s) to compare."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"granuleId"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"List[str]"})}),(0,n.jsx)(t.td,{children:"The unique ID of granule(s) to compare."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"startTimestamp"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamp"})}),(0,n.jsx)(t.td,{children:"Start time for cumulus_create_time date range to compare data."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"endTimestamp"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamp"})}),(0,n.jsx)(t.td,{children:"End time for cumulus_create_time date range to compare data."})]})]})]}),"\n",(0,n.jsx)(t.p,{children:"When querying ORCA for the information these filters will be AND together for a\ncomparison answer."}),"\n",(0,n.jsx)(t.p,{children:"The sections below provide information on how these filters relate with the\nexpected metadata objects, the attributes those data objects may need for comparison\nand investigation, and other items related to the data when making the comparison."}),"\n",(0,n.jsx)(t.p,{children:"The metadata objects include the following."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Provider"})," (providerId)"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Collection"})," (collectionId)"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Granule"})," (granuleId, startTimestamp, endTimestamp)"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"File"})," - Needed for comparison."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"File Version"})," - Needed for comparison, latest version only."]}),"\n"]}),"\n",(0,n.jsx)(t.h3,{id:"relationship-of-the-metadata-objects",children:"Relationship of the Metadata Objects"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["A ",(0,n.jsx)(t.strong,{children:"Provider"})," contains an unique ID and is made up of one or more Collections."]}),"\n",(0,n.jsxs)(t.li,{children:["A ",(0,n.jsx)(t.strong,{children:"Collection"})," contains an unique ID that contains the short name, and version and is made up of one or more Granules."]}),"\n",(0,n.jsxs)(t.li,{children:["A ",(0,n.jsx)(t.strong,{children:"Granule"})," contains an unique ID and is made up of one or more Files."]}),"\n",(0,n.jsxs)(t.li,{children:["A ",(0,n.jsx)(t.strong,{children:"File"})," contains a name unique to the ",(0,n.jsx)(t.em,{children:"Granule ID"})," and is made up of one or more File Versions."]}),"\n",(0,n.jsxs)(t.li,{children:["A ",(0,n.jsx)(t.strong,{children:"File Version"})," contains the versions, sizes, hashes and etags of a file along with pertinent dates."]}),"\n"]}),"\n",(0,n.jsx)(t.h3,{id:"potential-attributes-of-the-metadata-objects",children:"Potential Attributes of the Metadata Objects"}),"\n",(0,n.jsx)(t.p,{children:"The following provides the potential metadata attributes that need to be captured\nfor each object in order to properly filter and provide information back to Cumulus\nfor reconciliation and Operator investigation of discrepancies.\nA draft schema for how the objects would interact and be tied together can be\nseen below."}),"\n",(0,n.jsx)("img",{src:(0,s.A)("img/Research-Reconciliation-orca-inventory-schema.png"),zoomInPic:(0,s.A)("img/zoom-in.svg"),zoomOutPic:(0,s.A)("img/zoom-out.svg"),resetPic:(0,s.A)("img/zoom-pan-reset.svg")}),"\n",(0,n.jsx)(t.admonition,{title:"Optional Attributes",type:"note",children:(0,n.jsx)(t.p,{children:"When noted, optional attributes are items not strictly needed for reconciliation\nbut may provide value for additional enhancements which may occur in the future\nto query and filter the data for data management activities."})}),"\n",(0,n.jsx)(t.h4,{id:"provider-metadata-object",children:"Provider Metadata Object"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"provider_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"providerId that is provided by Cumulus."}),(0,n.jsx)(t.td,{children:"Must be unique."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"name"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Unique name of the provider."}),(0,n.jsx)(t.td,{children:"Optional but may provide more value for future items."})]})]})]}),"\n",(0,n.jsx)(t.h4,{id:"collection-metadata-object",children:"Collection Metadata Object"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"collection_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"collectionId that is provided by Cumulus."}),(0,n.jsx)(t.td,{children:"Must be unique per providerId."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"shortname"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Short name of the collection (AST_L1A)."}),(0,n.jsx)(t.td,{children:"Optional but may provide more value for future items."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"version"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Version of the collection (061)."}),(0,n.jsx)(t.td,{children:"Optional but may provide more value for future items."})]})]})]}),"\n",(0,n.jsxs)(t.p,{children:["I also considered adding attributes for collection configuration information like\nthe ",(0,n.jsx)(t.em,{children:"excluded file types"}),", ",(0,n.jsx)(t.em,{children:"default archive bucket"}),", and other ORCA configurations.\nThinking through it though, I felt it was better to leave these with Cumulus and\nperform a lookup if they are needed. This was primarily for two reasons. First,\nthere are really no need for them for reconciliation within ORCA. Second, keeping\nthe values in sync with changes made by operators through the Cumulus Dashboard\nseemed a bit challenging and did not appear to provide a real benefit."]}),"\n",(0,n.jsx)(t.h4,{id:"granule-metadata-object",children:"Granule Metadata Object"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Internal ORCA granule ID pseudo key."}),(0,n.jsx)(t.td,{children:"None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"collection_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Collection ID from Cumulus that references the Collections table."}),(0,n.jsx)(t.td,{children:"None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"cumulus_create_time"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamp"})}),(0,n.jsx)(t.td,{children:"createdAt time from Cumulus"}),(0,n.jsx)(t.td,{children:"None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"cumulus_granule_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"granuleId that is provided by Cumulus."}),(0,n.jsx)(t.td,{children:"Must be unique per collectionId"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"execution_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Step function execution ID from AWS."}),(0,n.jsx)(t.td,{children:"Unique ID automatically generated by AWS"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"ingest_time"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamp"})}),(0,n.jsx)(t.td,{children:"Date and time in UTC that the data was originally ingested into ORCA."}),(0,n.jsx)(t.td,{children:"None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"last_update"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamp"})}),(0,n.jsx)(t.td,{children:"Date and time in UTC that information was updated."}),(0,n.jsx)(t.td,{children:"None"})]})]})]}),"\n",(0,n.jsxs)(t.p,{children:["Note that the combination of the Cumulus Granule ID (cumulus_granule_id) and\nthe Cumulus Collection ID (collection_id) is unique in the\n",(0,n.jsx)(t.a,{href:"https://github.com/nasa/cumulus/blob/master/lambdas/db-migration/src/migrations/20201014105058_create_granules_table.ts",children:"Cumulus granules table"}),"."]}),"\n",(0,n.jsx)(t.h4,{id:"file-metadata-object",children:"File Metadata Object"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Internal ORCA file ID"}),(0,n.jsx)(t.td,{children:"None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"granule_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Granule that the file belongs to references the internal ORCA granule ID."}),(0,n.jsx)(t.td,{children:"None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"name"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Name of the file. (MOD14A1.061.2020245.hdf)"}),(0,n.jsx)(t.td,{children:"Must be unique per granuleId"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"orca_archive_location"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"ORCA S3 Glacier bucket the file resides in."}),(0,n.jsx)(t.td,{children:"None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"cumulus_archive_location"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Cumulus S3 bucket the file is expected to reside in."}),(0,n.jsx)(t.td,{children:"None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"key_path"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"S3 path to the file including the file name and extension, but not the bucket."}),(0,n.jsx)(t.td,{children:"Must be unique per archive location"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"ingest_time"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamp"})}),(0,n.jsx)(t.td,{children:"Date and time in UTC that the data was originally ingested into ORCA"}),(0,n.jsx)(t.td,{children:"None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"etag"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"etag of the file object in the AWS S3 Glacier bucket."}),(0,n.jsx)(t.td,{children:"None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"version"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"AWS provided version of the file."}),(0,n.jsx)(t.td,{children:"Must be unique per file name/key_path"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"size_in_bytes"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int"})}),(0,n.jsx)(t.td,{children:"Size in bytes of the file. From Cumulus ingest."}),(0,n.jsx)(t.td,{children:"Part of object passed to archive from Cumulus."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"hash"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Checksum hash of the file provided by Cumulus."}),(0,n.jsx)(t.td,{children:"Optional. Part of object passed to archive from Cumulus."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"hash_type"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Hash type used to calculate the hash value of the file."}),(0,n.jsx)(t.td,{children:"Optional. Part of object passed to archive from Cumulus."})]})]})]}),"\n",(0,n.jsxs)(t.p,{children:["Note that in Cumulus the combination of the bucket (cumulus_archive_location)\nand key (key_path) is unique in the ",(0,n.jsx)(t.a,{href:"https://github.com/nasa/cumulus/blob/master/lambdas/db-migration/src/migrations/20201014105102_create_files_table.ts",children:"Cumulus files table"}),"."]}),"\n",(0,n.jsx)(t.h4,{id:"file-version-object",children:"File Version Object"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"version"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"AWS provided version of the file."}),(0,n.jsx)(t.td,{children:"Must be unique per file name/key_path"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"is_latest"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"boolean"})}),(0,n.jsx)(t.td,{children:"AWS provided flag denoting that it is the latest version."}),(0,n.jsx)(t.td,{children:"Only one can be latest per file name/key_path. Depending of final table structure this may be optional."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"etag"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"AWS provided etag of the versioned file. Semi unique"}),(0,n.jsx)(t.td,{children:"Potentially optional maybe able to be used for internal comparisons and/or data management investigations."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"cumulus_etag"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Cumulus provided AWS etag of the file in Cumulus."}),(0,n.jsx)(t.td,{children:"Potentially optional. Would need to determine if this information passed along. May be helpful for data management comparisons."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"size_in_bytes"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"bigint"})}),(0,n.jsx)(t.td,{children:"Size in bytes of the file. From Cumulus ingest."}),(0,n.jsx)(t.td,{children:"Part of object passed to archive from Cumulus."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"hash"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Checksum hash of the file provided by Cumulus."}),(0,n.jsx)(t.td,{children:"Part of object passed to archive from Cumulus."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"hash_type"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Hash type used to calculate the hash value of the file."}),(0,n.jsx)(t.td,{children:"Part of object passed to archive from Cumulus."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"ingest_time"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamp"})}),(0,n.jsx)(t.td,{children:"Date and time in UTC that the file was ingested into ORCA"}),(0,n.jsx)(t.td,{children:"None"})]})]})]}),"\n",(0,n.jsxs)(t.p,{children:["It is possible that we may want to merge the ",(0,n.jsx)(t.strong,{children:"File Version Object"})," with the\n",(0,n.jsx)(t.strong,{children:"File Object"}),". If we were to merge the two objects, here are some things to\nconsider. By merging the objects we would likely only keep the latest version\ninformation of the file in the table. By doing this we do simplify reconciliation\nwith Cumulus but, then the only catalog of all the versions available for a file\nwould reside in the glacier S3 bucket. The implication of this is there is no other\nrecord of the various versions of the file. Also, we should need to query the S3\nbucket if the data manager wanted to inquire what versions were available for a\nfile in order to restore the proper version back or to identify versions that may\nbe eligible for deletions based on policy. If we merge the objects, we may want to\ncapture the total versions available for the file."]}),"\n",(0,n.jsx)(t.h3,{id:"return-metadata-needed-by-cumulus",children:"Return Metadata Needed by Cumulus"}),"\n",(0,n.jsx)(t.p,{children:"At a minimum, the following metadata should be returned back to Cumulus upon a\nsuccessful query for reconciliation return from ORCA. The data below is what\nis needed for reconciliation comparison and general metadata that may be needed\nby the end user to perform analysis on discrepancies."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Provider ID (providerId)"}),"\n",(0,n.jsx)(t.li,{children:"Collection ID (collectionId)"}),"\n",(0,n.jsx)(t.li,{children:"Shortname"}),"\n",(0,n.jsx)(t.li,{children:"collection Version"}),"\n",(0,n.jsx)(t.li,{children:"Granule ID (granuleId)"}),"\n",(0,n.jsx)(t.li,{children:"Cumulus create time"}),"\n",(0,n.jsx)(t.li,{children:"Execution ID"}),"\n",(0,n.jsx)(t.li,{children:"Granule Ingest Date (ORCA) - may also be referred to as a Create Date."}),"\n",(0,n.jsx)(t.li,{children:"Granule Last Update (ORCA)"}),"\n",(0,n.jsx)(t.li,{children:"File Name"}),"\n",(0,n.jsx)(t.li,{children:"ORCA Location - archive bucket + archive path"}),"\n",(0,n.jsx)(t.li,{children:"Cumulus Archive Location"}),"\n",(0,n.jsx)(t.li,{children:"Key Path"}),"\n",(0,n.jsx)(t.li,{children:"Etag"}),"\n",(0,n.jsx)(t.li,{children:"File Size"}),"\n",(0,n.jsx)(t.li,{children:"File Hash (Optional)"}),"\n",(0,n.jsx)(t.li,{children:"File Hash Type (Optional)"}),"\n",(0,n.jsx)(t.li,{children:"File Version (always send back latest version to compare)"}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"A rough structure may look like the following below. In order to simplify\ncomparisons, only the latest file version information will be returned. Enhancements\nwe will need consider later include items like updating the latest flag in the\ndatabase and glacier on a file version when doing a recovery."}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-json",children:'{\n  "anotherPage": false,\n  "granules": [\n    {\n      "providerId": "lpdaac",\n      "collectionId": "MOD14A1___061",\n      "id": "MOD14A1.061.A23V45.2020235",\n      "createdAt": "2020-01-01T23:00:00Z",\n      "executionId": "u654-123-Yx679",\n      "ingestDate": "2020-01-01T23:00:00Z",\n      "lastUpdate": "2020-01-01T23:00:00Z",\n      "files": [\n        {\n          "name": "MOD14A1.061.A23V45.2020235.2020240145621.hdf",\n          "cumulusArchiveLocation": "cumulus-bucket",\n          "orcaArchiveLocation": "orca-archive",\n          "keyPath": "MOD14A1/061/032/MOD14A1.061.A23V45.2020235.2020240145621.hdf",\n          "sizeBytes": 100934568723,\n          "hash": "ACFH325128030192834127347",\n          "hashType": "SHA-256",\n          "version": "VXCDEG902"\n        },\n        ...\n      ]\n    },\n    ...\n  ]\n}\n'})}),"\n",(0,n.jsx)(t.p,{children:"Some items we will need to think about include managing paging (start/stop) for\nlarge returns and limiting size of the message across the wire.\nAdditionally, results should be ordered by granule_id."}),"\n",(0,n.jsx)(t.h3,{id:"potential-orca-reconciliation-data-reporting-architecture",children:"Potential ORCA Reconciliation Data Reporting Architecture"}),"\n",(0,n.jsx)(t.p,{children:"The following provides a rough, high level architecture for reporting the ORCA\nholdings to Cumulus. When providing data back to Cumulus, the solution should be\nable to handle the filters supplied and return back the needed data. In addition,\nthe solution should be extensible and should allow for potential changes in the\nunderlying data structure or storage engine as ORCA should be able to handle AWS\nPostgreSQL RDS, AWS Aurora PostgreSQL, and AWS Aurora PostgreSQL Serverless\nofferings."}),"\n",(0,n.jsx)("img",{src:(0,s.A)("img/Research-Reconciliation-Cumulus-Reconcile.png"),zoomInPic:(0,s.A)("img/zoom-in.svg"),zoomOutPic:(0,s.A)("img/zoom-out.svg"),resetPic:(0,s.A)("img/zoom-pan-reset.svg")}),"\n",(0,n.jsx)(t.h2,{id:"populating-the-metadata",children:"Populating the metadata"}),"\n",(0,n.jsx)(t.p,{children:"Populating the metadata objects with the proper metadata will need to come from\nvarious sources. The sections below will go through thoughts and ideas of where\nthe metadata will originate from to populate the objects and potential ideas on\nwhat the underlying architecture may look like to perform the tasks."}),"\n",(0,n.jsx)(t.h3,{id:"automated-cumulus-ingest-workflow",children:"Automated Cumulus Ingest Workflow"}),"\n",(0,n.jsxs)(t.p,{children:["The conventional way of populating the objects with metadata would be through\nthe normal Cumulus ingest workflow that contains ORCA's ",(0,n.jsx)(t.code,{children:"copy_to_archive"})," lambda.\nThe ",(0,n.jsx)(t.code,{children:"copy_to_archive"})," lambda would need to be modified to take or pull additional\nmetadata needed to associate a granule's files to Cumulus, like ",(0,n.jsx)(t.code,{children:"providerId"}),",\n",(0,n.jsx)(t.code,{children:"collectionId"}),", ",(0,n.jsx)(t.code,{children:"granuleId"}),", and various other file metadata information. The\nadditional collected metadata would sent to a queue to be written to the ORCA\ncatalog. The body sent to the queue would have enough information for another\nORCA lambda to write and/or update the records for the various objects in the ORCA\ncatalog."]}),"\n",(0,n.jsxs)(t.p,{children:["Note that this new database write lambda or the ",(0,n.jsx)(t.code,{children:"copy_to_archive"})," lambda may need\nto make some additional queries to the S3 ORCA bucket to pull information like\nversion and other values. Looking at the original ",(0,n.jsx)(t.code,{children:"copy_to_archive"}),", ",(0,n.jsx)(t.code,{children:"s3.copy"}),"\nis used to copy data to the ORCA archive. Based on initial research located\n",(0,n.jsx)(t.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.copy",children:"here"}),",\nthe ",(0,n.jsx)(t.code,{children:"s3.copy"})," command does not return any information. See the test performed\nbelow. Because of this, we will likely need to perform a listing on the object to\nget additional information like the S3 object version as seen in the sample below.\nSome items to consider when looking at the options for retrieving the additional\nmetadata include:"]}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.em,{children:"speed"})," - How fast can I get the needed metadata?"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.em,{children:"cost"})," - What is the cost impact of additional gets on the s3 bucket?"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.em,{children:"complexity"})," - Where is the best place to put these additional gets? Is the overall design and/or implementation to complex?"]}),"\n"]}),"\n",(0,n.jsx)(t.h4,{id:"boto3-copy-test",children:"Boto3 Copy Test"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:'import boto3\n\n# Create the Client\ns3_client = boto3.resource(\'s3\')\n\n# Get a source and destination to copy\ncopy_source = {"Bucket": "orca-sandbox-s3-provider", "Key": "MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065111.hdf"}\ncopy_destination = "orca-sandbox-archive"\n\n# perform the copy command\ncopy_command = s3_client.meta.client.copy(copy_source, copy_destination, copy_source["Key"])\n\n# Return results\nprint(copy_command)\nNone\n'})}),"\n",(0,n.jsx)(t.h4,{id:"boto3-get-additional-file-information",children:"Boto3 Get Additional File Information"}),"\n",(0,n.jsxs)(t.p,{children:["This would occur after an ",(0,n.jsx)(t.code,{children:"s3.copy"})," and assumes that the copy is synchronous and\nthat the file is not be ingested in parallel in a separate ingest pipeline that\nwould lead to a collision."]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:"import boto3\n\n# Create the Client\ns3_client = boto3.resource('s3')\n\n# Get a source and destination to copy\ncopy_source = {\"Bucket\": \"orca-sandbox-s3-provider\", \"Key\": \"MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065111.hdf\"}\ncopy_destination = \"orca-sandbox-archive\"\n\n# Get the versioning information\nfile_versions = s3_client.meta.client.list_object_versions(Bucket=copy_destination, Prefix=copy_source[\"Key\"] )\n\nfor version in file_versions[\"Versions\"]:\n    if version[\"IsLatest\"]:\n        print(version)\n\n\n# Return results\n{\n    'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"',\n    'Size': 6,\n    'StorageClass': 'STANDARD',\n    'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065111.hdf',\n    'VersionId': 'null',\n    'IsLatest': True,\n    'LastModified': datetime.datetime(2021, 5, 18, 16, 25, 58, tzinfo=tzutc()),\n    'Owner': {\n        'DisplayName': 'gsfc-esdis-edc-lpdaac-sandbox-7343-root',\n        'ID': '4d102362d8dc848404655e5418ff76cd342418b8d2ea3a04aa5db133bd6ac1db'\n    }\n}\n"})}),"\n",(0,n.jsxs)(t.p,{children:["Note that the data we would likely want are ETag, VersionId, Size, and LastModified.\nIn the example above, the file I used was not part of a versioned S3 bucket thus\nthe ",(0,n.jsx)(t.code,{children:"null"})," value for VersionId."]}),"\n",(0,n.jsx)(t.h4,{id:"boto3-use-multipart-copy",children:"Boto3 Use Multipart Copy"}),"\n",(0,n.jsx)(t.p,{children:"In addition to the items above, I also looked at multipart copy which would\nreturn the information natively, but there is a 5Mb minimum size limit when\nusing this functionality which is not small enough for some of the small files\nwe may encounter. Reference information on multipart copy is provided below."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.upload_part_copy",children:"Boto3 Upload Part Copy Command"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://docs.aws.amazon.com/AmazonS3/latest/API/API_UploadPartCopy.html",children:"AWS API Upload Part Copy Reference"})}),"\n"]}),"\n",(0,n.jsx)(t.h3,{id:"manually-run-orca-ingest-workflows",children:"Manually Run ORCA Ingest Workflows"}),"\n",(0,n.jsxs)(t.p,{children:["When manually running a workflow to ingest data into ORCA, it is assumed that the\nsame modified ",(0,n.jsx)(t.code,{children:"copy_to_archive"})," lambda used in an automated workflow would be used\nin the manual workflow. This would mean the translation lambda used to pass the\nproper information from the Cumulus Dashboard call to the ",(0,n.jsx)(t.code,{children:"copy_to_archive"})," lambda\nwould need to retrieve and provide information similar to the information that\nis provided by the ",(0,n.jsx)(t.code,{children:"moveGranules"})," lambda in the normal workflow. The translation\nlambda will likely need to leverage Cumulus API calls to get information related\nto the files and granule from Cumulus. The following cards that are planned to be\nworked during PI 21.2 contain information related to this type of workflow and\ntranslation lambda. See the list below."]}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://bugs.earthdata.nasa.gov/browse/ORCA-173",children:"Understanding the Cumulus Dashboard Workflow Call Output"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://bugs.earthdata.nasa.gov/browse/ORCA-175",children:"Creating a Translate Lambda for Cumulus Dashboard Inputs for copy_to_archive"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://bugs.earthdata.nasa.gov/browse/ORCA-182",children:"Creating a Workflow for Ingesting Missing Files Into ORCA"})}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"Work related to reconciliation will likely require modifications to the translation\nlambda to pull additional information needed. The following are resources that may\nbe utilized to gather additional granule and file information from Cumulus if needed.\nSee the resource links below."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://nasa.github.io/cumulus-api/#retrieve-granule",children:"Cumulus API Get Granule Information"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://nasa.github.io/cumulus-api/#bulk-operations",children:"Cumulus API Bulk Operations"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#c-concept-id",children:"CMR API Get Granule Information"})}),"\n"]}),"\n",(0,n.jsxs)(t.p,{children:["Note that the CMR call may not be necessary depending on the required metadata\nneeded. In addition, the CMR concept ID call can be retrieved from the ",(0,n.jsx)(t.code,{children:"cmrLink"}),"\nkey in the Cumulus API Get Granule Information. There may be some permission\nissues to work through if the collection is not public or the granule is\nhidden for some reason which means we would need to perform a login with a user\nthat would have access to see all of the providers holdings. Additional research\nmay need to be performed to better understand how to gather this information."]}),"\n",(0,n.jsx)(t.h3,{id:"back-population-of-the-orca-catalog",children:"Back Population of the ORCA Catalog"}),"\n",(0,n.jsx)(t.p,{children:"Generally, the first two options listed will handle most use cases for adding\ninformation to the ORCA archive. However, for users that already have ORCA\ninstallations that are older than or equal to v3.x, a new workflow will need to\nbe created to back populate the ORCA metadata catalog. Ideally, this workflow\nwould be kicked off as part of the ORCA installation and/or migration."}),"\n",(0,n.jsx)(t.p,{children:"As a general breakdown of the flow, the Lambda or Workflow will need to do the\nfollowing:"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsx)(t.li,{children:"Query Cumulus looking for Collections configured for ORCA."}),"\n",(0,n.jsx)(t.li,{children:"Using the list of Collections configured for ORCA, retrieve the granule and file information."}),"\n",(0,n.jsx)(t.li,{children:"Get a list of the files in each ORCA bucket."}),"\n",(0,n.jsx)(t.li,{children:"Match attributes from the ORCA file list like file name, key path, and size to file(s) in the Cumulus list."}),"\n",(0,n.jsxs)(t.li,{children:["Create a message body from the information similar to what ",(0,n.jsx)(t.code,{children:"copy_to_granule"})," will perform."]}),"\n",(0,n.jsx)(t.li,{children:"Send the message body to the SQS FIFO queue so the database lambda can write the record to the database."}),"\n"]}),"\n",(0,n.jsxs)(t.p,{children:["There are likely several ways to optimize this flow. The above is just a general\nconcept to help get the information needed to match files. Collection regex information\ncould also possibly be used. The Cumulus ",(0,n.jsx)(t.a,{href:"https://github.com/nasa/cumulus/blob/master/lambdas/db-migration/src/migrations/20201014105102_create_files_table.ts",children:"files table"}),"\nallows us to match key based on our listing, but the combination of key and Cumulus\nbucket are unique unique which means we could match multiple records based on\nkey alone."]}),"\n",(0,n.jsx)(t.p,{children:'Note that this concept of back populating by matching data is not 100% accurate\nand is a best attempt to pull data and match it without "re-ingesting" items\nback into ORCA. This approach will likely need lots of logging and reporting to\nlet end users know where discrepancies and best guesses or misses occur. We\nshould also talk with end users about this option prior to implementing to\ndetermine if this is needed.'}),"\n",(0,n.jsxs)(t.p,{children:["After discussions with the ",(0,n.jsx)(t.a,{href:"https://wiki.earthdata.nasa.gov/display/CUMULUS/ORCA+Working+Group",children:"ORCA Working Group"}),"\nduring the ",(0,n.jsx)(t.a,{href:"https://wiki.earthdata.nasa.gov/display/CUMULUS/2021-06-02+ORCA+Meeting+Notes",children:"June meeting"}),"\nthe concept above was discussed. The general consensus from the group was that re-population\nof ORCA through a standalone workflow similar to the items laid out in the\n",(0,n.jsx)(t.a,{href:"#manually-run-orca-ingest-workflows",children:"manual run"})," was the best option. In addition,\nthe question of whether the back population method described above was a\nworthwhile path to pursue was posed on the orca Slack channel and the users\ncurrently using ORCA all agreed they would rather re-ingest into ORCA as seen by\nthe Slack thread ",(0,n.jsx)(t.a,{href:"https://eosdis.slack.com/archives/CSXEM5MPX/p1622735484015400",children:"here"}),"."]}),"\n",(0,n.jsx)(t.h3,{id:"potential-orca-catalog-population-architecture",children:"Potential ORCA Catalog Population Architecture"}),"\n",(0,n.jsxs)(t.p,{children:["The following is a potential architecture for populating the ORCA catalog under\nnormal use cases. Note that the SQS queue and ",(0,n.jsx)(t.code,{children:"orca_catalog_ingest"})," lambda could\nbe replaced with a GraphQL server if deemed appropriate."]}),"\n",(0,n.jsx)("img",{src:(0,s.A)("img/Research-Reconciliation-Catalog-Population.png"),zoomInPic:(0,s.A)("img/zoom-in.svg"),zoomOutPic:(0,s.A)("img/zoom-out.svg"),resetPic:(0,s.A)("img/zoom-pan-reset.svg")}),"\n",(0,n.jsx)(t.h2,{id:"possible-technologies-for-enabling-the-work",children:"Possible Technologies for Enabling the Work"}),"\n",(0,n.jsxs)(t.p,{children:["The following is a short list of technologies that could be leveraged during this\nwork. These technologies fall within current architectures for Cumulus and\nextensions and may contribute to more rapid development of features as we progress.\nA full list of AWS services available in NGAP is available ",(0,n.jsx)(t.a,{href:"https://wiki.earthdata.nasa.gov/display/ESKB/AWS+Services+Approval+Status+Page",children:"here"}),"."]}),"\n",(0,n.jsx)(t.h3,{id:"api-gateway",children:"API Gateway"}),"\n",(0,n.jsxs)(t.p,{children:["The ORCA API Gateway provides an entry point for the Cumulus dashboard and users\nto interact directly with ORCA. For more information on the ORCA API gateway, see\nthe ",(0,n.jsx)(t.a,{href:"/cumulus-orca/docs/developer/research/research-APIGateway",children:"API Gateway research page"}),". All reconciliation\ncalls from Cumulus should occur through the ORCA API Gateway."]}),"\n",(0,n.jsx)(t.h3,{id:"graphql",children:"GraphQL"}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.a,{href:"https://graphql.org/learn/",children:"GraphQL"})," is a query language for APIs. This is an\nadditional research spike topic. The promise of this route further consolidates\nour database read/write code while at the same time providing a single API endpoint\nfor clients (both ORCA and Cumulus) to retrieve the data from ORCA. This technology\nthough adding some complexity could simplify some code and design aspects."]}),"\n",(0,n.jsx)(t.p,{children:"Research aspects would include GraphQL server to use (COTS or home built). Impacts\nto AWS account (cost, speed, capabilities, security). Synergy with other projects\nlike Cumulus."}),"\n",(0,n.jsx)(t.p,{children:"Some initial resources to start would include the following:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://www.moesif.com/blog/graphql/technical/Ways-To-Add-GraphQL-To-Your-Postgres-Database-Comparing-Hasura-Prisma-and-Others/",children:"GraphQL Servers (prebuilt)"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://www.howtographql.com/choose/",children:"Build your Own GraphQL Server"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://www.edx.org/course/exploring-graphql-a-query-language-for-apis",children:"GraphQL classes"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://git.earthdata.nasa.gov/projects/CMRQL/repos/hackfest-cmr-graphql/browse",children:"GraphQL Example with CMR"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://www.apollographql.com/docs/apollo-server/deployment/lambda/",children:"Using Apollo Server as a Lambda"})}),"\n"]}),"\n",(0,n.jsx)(t.h3,{id:"sqs",children:"SQS"}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.a,{href:"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html",children:"AWS SQS FIFO queues"}),"\nshould be used to manage the records to be written to the ORCA database. This\nallows the team to decouple the database code from several lambdas and centralize\nthe code to one area. This may or may not be needed if GraphQL is utilized."]}),"\n",(0,n.jsx)(t.h3,{id:"aws-postgresql-rds-offerings",children:"AWS PostgreSQL RDS Offerings"}),"\n",(0,n.jsxs)(t.p,{children:["To better align with Cumulus, ORCA will utilize the AWS PostgreSQL RDS offerings.\nSee notes on the ORCA transition to the ORCA database ",(0,n.jsx)(t.a,{href:"https://wiki.earthdata.nasa.gov/display/ORCA/ORCA+Migration+to+Cumulus+RDS",children:"here"}),".\nThe resultant code from the reconciliation work should be able to handle working\nwith a PostgreSQL back end. Both PostgreSQL RDS and Amazon Aurora are viable back\nend choices that may be utilized. See a comparison article on the databases\n",(0,n.jsx)(t.a,{href:"https://aws.amazon.com/blogs/database/is-amazon-rds-for-postgresql-or-amazon-aurora-postgresql-a-better-choice-for-me/",children:"here"}),"."]}),"\n",(0,n.jsx)(t.h3,{id:"nodejs-knex--python-sqlalchemy",children:"NodeJS (Knex) / Python (SQLAlchemy)"}),"\n",(0,n.jsx)(t.p,{children:"An agnostic language framework for working with the database should be used some\noptions include but are not limited to the items described below. Utilizing a\nmore general API may help manage changes to the back end database engine with\nlittle or no code changes."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.a,{href:"http://knexjs.org/",children:"Nodejs and Knex"})," is what the Cumulus team currently\nutilizes for database interactions. Implementation could follow best practices\nalready established by the Cumulus team."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.a,{href:"https://docs.sqlalchemy.org/en/14/core/",children:"Python and SQLAlchemy Core"})," is currently\nbeing used in some ORCA code."]}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"comparison-between-orca-s3-and-the-orca-catalog",children:"Comparison between ORCA S3 and the ORCA Catalog"}),"\n",(0,n.jsxs)(t.p,{children:["In addition to the comparison between the Cumulus catalog and ORCA, ORCA will\nalso need to manage and maintain the catalog holdings between the ORCA database\nand the actual contents of the ORCA S3 buckets. This will require comparing the\n",(0,n.jsx)(t.em,{children:"Key"}),", ",(0,n.jsx)(t.em,{children:"LastModified"}),", ",(0,n.jsx)(t.em,{children:"ETag"}),", and ",(0,n.jsx)(t.em,{children:"Size"})," keys to the of the files in the bucket\nto the ORCA holdings catalog. Discrepancies should be reported back to the user\nand detail orphan and missing files. We could possibly create a temporary reporting\ntable to hold these values that the Cumulus Dashboard could display for us."]}),"\n",(0,n.jsx)(t.p,{children:"Some things to think through when designing this solution are factors of scale\nand managing them. To provide some thought and guidance, LP DAAC (one of the larger\nDAACs) has approximately 300 million files in the archive and growing. If all the\nfiles are also stored in ORCA, we will need to reconcile all the files in a smart\nand somewhat quick way on a semi regular basis."}),"\n",(0,n.jsx)(t.p,{children:"Ideally, this reconciliation would occur on a regular schedule using a rule and\nreports would be stored in the database for users to retrieve the information.\nAdditionally, the code should handle failures gracefully and be able to pick up\nwhere it left off either gathering the current contents in S3 or performing the\nORCA catalog internal comparisons with S3."}),"\n",(0,n.jsx)(t.p,{children:"Future enhancements may include displaying the information on the Cumulus dashboard,\nnotifying operators via email or other means of discrepancies, or automated healing\nof the archive based on reconciliation results."}),"\n",(0,n.jsx)(t.h3,{id:"getting-a-listing-from-aws-s3",children:"Getting a Listing from AWS S3"}),"\n",(0,n.jsxs)(t.p,{children:["To get a file listing of an S3 bucket, the ",(0,n.jsx)(t.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.list_objects_v2",children:"list_objects_v2 method"}),"\ncan be used from the boto3 library. An example of the usage can be seen below.\nSome notable items if this library is used includes the following."]}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Only a max of 1000 objects are returned per call. Additional logic will be needed to page through and get all of the results."}),"\n",(0,n.jsx)(t.li,{children:"The listing can be filtered by prefix. Possibly some room here to add configuration to look at the collection lever if a collection can be denoted by prefix."}),"\n",(0,n.jsx)(t.li,{children:"Version information is not included, only the latest file information is provided."}),"\n",(0,n.jsx)(t.li,{children:"An additional call will need to be made per object to look at versions available for a file."}),"\n",(0,n.jsx)(t.li,{children:"Only limited fields are returned from the call."}),"\n",(0,n.jsx)(t.li,{children:"Each list call does cost in AWS (tiny fractions of a cent)."}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"Other considerations. It may be easier to load the data from the listing calls\ninto a temporary table in the database and perform a handful of queries to find\nthe delta information instead of looping through and doing a comparison in memory."}),"\n",(0,n.jsx)(t.h4,{id:"example-using-list_objects_v2",children:"Example Using list_objects_v2"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:"import boto3\n\n# Set the variables\ns3_client = boto3.resource('s3')\ncopy_destination = \"orca-sandbox-archive\"\n\n# Get the listing\nfiles = s3_client.meta.client.list_objects_v2(Bucket=copy_destination)\n\n# Print the contents\nfor file in files[\"Contents\"]:\n    print(file)\n\n# Results\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065104.cmr.xml', 'LastModified': datetime.datetime(2020, 12, 15, 20, 4, 8, tzinfo=tzutc()), 'ETag': '\"aaf96912124e107bf22016c7695fdcef\"', 'Size': 2320, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065104.hdf', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 58, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065104.hdf.met', 'LastModified': datetime.datetime(2020, 12, 15, 20, 4, 7, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065104_ndvi.jpg', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 59, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065105.cmr.xml', 'LastModified': datetime.datetime(2020, 12, 17, 16, 35, 22, tzinfo=tzutc()), 'ETag': '\"b4b1ea93026eece5390278d97bfd5c3e\"', 'Size': 2320, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065105.hdf', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 58, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065105.hdf.met', 'LastModified': datetime.datetime(2020, 12, 17, 16, 35, 22, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065105_ndvi.jpg', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 58, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065106.cmr.xml', 'LastModified': datetime.datetime(2020, 12, 17, 17, 5, 43, tzinfo=tzutc()), 'ETag': '\"67f535ab5d6398c2181ab7cf4763f84b\"', 'Size': 2320, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065106.hdf', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 58, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065106.hdf.met', 'LastModified': datetime.datetime(2020, 12, 17, 17, 5, 42, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065106_ndvi.jpg', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 58, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065107.cmr.xml', 'LastModified': datetime.datetime(2020, 12, 17, 20, 58, 55, tzinfo=tzutc()), 'ETag': '\"a71512f2cc5aa43edbf3573c76ccf5aa\"', 'Size': 2320, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065107.hdf', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 58, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065107.hdf.met', 'LastModified': datetime.datetime(2020, 12, 17, 20, 58, 54, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065107_ndvi.jpg', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 59, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065108.cmr.xml', 'LastModified': datetime.datetime(2020, 12, 18, 19, 10, 16, tzinfo=tzutc()), 'ETag': '\"6d76238799f45466a9431a9187aa5c70\"', 'Size': 2320, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065108.hdf', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 58, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065108.hdf.met', 'LastModified': datetime.datetime(2020, 12, 18, 19, 10, 14, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065108_ndvi.jpg', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 59, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065109.cmr.xml', 'LastModified': datetime.datetime(2020, 12, 18, 19, 19, 21, tzinfo=tzutc()), 'ETag': '\"f7ffec3ced795379e2346183221bd5e8\"', 'Size': 2320, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065109.hdf', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 57, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065109.hdf.met', 'LastModified': datetime.datetime(2020, 12, 18, 19, 19, 20, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065109_ndvi.jpg', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 57, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065110.cmr.xml', 'LastModified': datetime.datetime(2020, 12, 18, 19, 28, 44, tzinfo=tzutc()), 'ETag': '\"9fe1b5cf984cd64b8b7c31b49560ca6e\"', 'Size': 2320, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065110.hdf', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 57, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065110.hdf.met', 'LastModified': datetime.datetime(2020, 12, 18, 19, 28, 44, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065110_ndvi.jpg', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 57, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065111.hdf', 'LastModified': datetime.datetime(2021, 5, 18, 16, 25, 58, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'STANDARD'}\n{'Key': 'MOD09GQ/006/MOD09GQ.A2017025.h21v00.006.2017034065111_ndvi.jpg', 'LastModified': datetime.datetime(2021, 3, 23, 16, 59, 58, tzinfo=tzutc()), 'ETag': '\"81f4b6c158d25f1fe916ea52e99d1700\"', 'Size': 6, 'StorageClass': 'GLACIER'}\n"})}),"\n",(0,n.jsx)(t.h3,{id:"potential-internal-reconciliation-architecture",children:"Potential Internal Reconciliation Architecture"}),"\n",(0,n.jsx)(t.p,{children:"The following provides an architecture of how ORCA internal reconciliation\nmay work in an AWS environment with Cumulus. The architecture uses AWS' S3 Inventory report\ncombined with S3 triggering to fire the\ncomparison off on a normal schedule. Likely the running of this type of job will\nneed to scale.\nWhen returning results through the API, it is recommended that we use a \"path\" parameter that filters based on the file's 'Key'.\nThis will allow Cumulus to build values such as collection into a filter so long\nas they construct keys using it."}),"\n",(0,n.jsx)("img",{src:(0,s.A)("img/Research-Reconciliation-Internal-Reconcile.png"),zoomInPic:(0,s.A)("img/zoom-in.svg"),zoomOutPic:(0,s.A)("img/zoom-out.svg"),resetPic:(0,s.A)("img/zoom-pan-reset.svg")}),"\n",(0,n.jsx)(t.h3,{id:"s3-inventory-report",children:"S3 Inventory Report"}),"\n",(0,n.jsx)(t.p,{children:"S3 Inventory reports are created on S3 buckets and post information about that bucket's contents to another bucket.\nFor our purposes, the following options must be checked:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Size"}),"\n",(0,n.jsx)(t.li,{children:"Last modified"}),"\n",(0,n.jsx)(t.li,{children:"Storage class"}),"\n",(0,n.jsx)(t.li,{children:"ETag"}),"\n"]}),"\n",(0,n.jsxs)(t.p,{children:["Additionally, set ",(0,n.jsx)(t.code,{children:"Object versions"})," to ",(0,n.jsx)(t.code,{children:"Include all versions"}),"."]}),"\n",(0,n.jsx)(t.h3,{id:"potential-internal-reporting-database-structure",children:"Potential Internal Reporting Database Structure"}),"\n",(0,n.jsx)(t.p,{children:"The objects needed for managing ORCA internal reconciliation and reporting are\nprovided in detail below."}),"\n",(0,n.jsx)(t.p,{children:"An example schema showing how the objects interact and would be tied together is\nshown below."}),"\n",(0,n.jsx)("img",{src:(0,s.A)("img/Research-Reconciliation-orca-internal-reconciliation-schema.png"),zoomInPic:(0,s.A)("img/zoom-in.svg"),zoomOutPic:(0,s.A)("img/zoom-out.svg"),resetPic:(0,s.A)("img/zoom-pan-reset.svg")}),"\n",(0,n.jsx)(t.h4,{id:"status-table-reconcile_status",children:"Status Table reconcile_status"}),"\n",(0,n.jsx)(t.p,{children:"Reference table for valid status values and status order."}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int2"})}),(0,n.jsx)(t.td,{children:"Status ID."}),(0,n.jsx)(t.td,{children:"Primary Key"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"value"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Human readable status value."}),(0,n.jsx)(t.td,{})]})]})]}),"\n",(0,n.jsx)(t.h4,{id:"internal-reconciliation-jobs-table-reconcile_job",children:"Internal Reconciliation Jobs Table reconcile_job"}),"\n",(0,n.jsx)(t.p,{children:"This table would capture internal reconciliation job information. Below is a\nsampling of attributes that may be needed. Based on design and implementation,\nadditional attributes may be required. This table, in particular may need additional\nitems for managing jobs."}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int2"})}),(0,n.jsx)(t.td,{children:"Unique Job ID."}),(0,n.jsx)(t.td,{children:"Primary Key"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"orca_archive_location"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"ORCA S3 Archive bucket the reconciliation targets."}),(0,n.jsx)(t.td,{children:"Location in S3."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"status_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int8"})}),(0,n.jsx)(t.td,{children:"Current status of the job."}),(0,n.jsx)(t.td,{children:"Generally reflect the stages of reconciliation."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"inventory_creation_time"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamptz"})}),(0,n.jsx)(t.td,{children:"Inventory report initiation time from the s3 manifest."}),(0,n.jsx)(t.td,{children:"Cannot be NULL"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"start_time"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamptz"})}),(0,n.jsx)(t.td,{children:"Start time of the job."}),(0,n.jsx)(t.td,{children:"Cannot be NULL"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"last_update"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamptz"})}),(0,n.jsx)(t.td,{children:"Last time the status was updated."}),(0,n.jsx)(t.td,{children:"Cannot be NULL"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"end_time"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamptz"})}),(0,n.jsx)(t.td,{children:"End time of the job."}),(0,n.jsx)(t.td,{children:"NULLABLE column"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"error_message"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Job error message in cases of failure."}),(0,n.jsx)(t.td,{children:"NULLABLE column"})]})]})]}),"\n",(0,n.jsx)(t.h4,{id:"s3-inventory-temporary-table-reconcile_s3_object",children:"S3 Inventory Temporary Table reconcile_s3_object"}),"\n",(0,n.jsx)(t.p,{children:"This is a temporary object that would store the listing from the S3 bucket for\ncomparison."}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"job_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int8"})}),(0,n.jsx)(t.td,{children:"Reconcile job the listing is a part of."}),(0,n.jsx)(t.td,{children:"Many to one relationship with the jobs table."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"orca_archive_location"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"ORCA S3 Archive bucket the file resides in."}),(0,n.jsx)(t.td,{children:"Location in S3."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"key_path"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Key key value from S3 listing."}),(0,n.jsxs)(t.td,{children:["Should be able to match to the key_path in the ORCA catalog ",(0,n.jsx)(t.em,{children:"File"})," metadata object. Must be unique."]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"etag"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"ETag key value from S3 listing."}),(0,n.jsxs)(t.td,{children:["Should be able to match to the orca_etag value in the ORCA catalog ",(0,n.jsx)(t.em,{children:"File"})," metadata object."]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"last_update"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamptz"})}),(0,n.jsx)(t.td,{children:"LastModified key value from the S3 listing."}),(0,n.jsxs)(t.td,{children:["Should be able to match the last_update value in the ORCA catalog ",(0,n.jsx)(t.em,{children:"File"})," metadata object."]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"size_in_bytes"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int8"})}),(0,n.jsx)(t.td,{children:"Size key value from the S3 listing."}),(0,n.jsxs)(t.td,{children:["Should be able to match the size value in the ORCA catalog ",(0,n.jsx)(t.em,{children:"File"})," metadata object."]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"storage_class"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"StorageClass key value from the S3 listing."}),(0,n.jsxs)(t.td,{children:["May be used as a filter to exclude newly added items by excluding those with a value of ",(0,n.jsx)(t.em,{children:"STANDARD"})]})]})]})]}),"\n",(0,n.jsx)(t.h4,{id:"internal-reconciliation-reporting-table-orphaned-files-reconcile_orphan_report",children:"Internal Reconciliation Reporting Table Orphaned Files reconcile_orphan_report"}),"\n",(0,n.jsx)(t.p,{children:"This table would capture the files that reside in S3 but have no match in the\nORCA catalog. Generally, these files would be deleted or investigated to see if\nitems need to be re-ingested into ORCA.\nNote that entries with a last_update time\nafter or immediately before the job's start_time may not have catalog entries yet\ndue to a slight delay in the catalog population. This should be indicated when\nreporting results."}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"job_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int8"})}),(0,n.jsx)(t.td,{children:"Reconcile job the report is a part of."}),(0,n.jsx)(t.td,{children:"FK constraint back to the jobs table with a many to one relationship."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"key_path"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Key key value from S3 listing."}),(0,n.jsx)(t.td,{})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"etag"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"ETag key value from S3 listing."}),(0,n.jsx)(t.td,{})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"last_update"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamptz"})}),(0,n.jsx)(t.td,{children:"LastModified key value from the S3 listing."}),(0,n.jsx)(t.td,{})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"size_in_bytes"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int8"})}),(0,n.jsx)(t.td,{children:"Size key value from the S3 listing."}),(0,n.jsx)(t.td,{})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"storage_class"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"StorageClass key value from the S3 listing."}),(0,n.jsx)(t.td,{})]})]})]}),"\n",(0,n.jsx)(t.h4,{id:"internal-reconciliation-reporting-table-s3-missing-reconcile_phantom_report",children:"Internal Reconciliation Reporting Table S3 Missing reconcile_phantom_report"}),"\n",(0,n.jsx)(t.p,{children:"This table captures files that have records in the orca catalog, but are missing from S3.\nThese files may have been deleted outside or a proper deletion flow, and may need to have their catalog entries manually cleared.\nNote that any entries with an orca_last_update after the job's\nstart_time may show as an error due to race conditions with the catalog update\nprocess, and should be displayed as such when reporting results."}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"job_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int8"})}),(0,n.jsx)(t.td,{children:"Reconcile job the report is a part of."}),(0,n.jsx)(t.td,{children:"FK constraint back to the jobs table with a many to one relationship."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"collection_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Collection ID from the ORCA Collection object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"granule_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Granule ID from the ORCA Granule object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"file_name"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"File name from the ORCA File object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"key_path"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Key path that includes the file name from the ORCA File object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"orca_etag"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Etag value from the ORCA File object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"orca_last_update"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamptz"})}),(0,n.jsx)(t.td,{children:"Last Update value from the ORCA File object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"orca_size"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int8"})}),(0,n.jsx)(t.td,{children:"Size value from the ORCA File object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]})]})]}),"\n",(0,n.jsx)(t.h4,{id:"internal-reconciliation-reporting-table-catalog-missing-or-mismatches-reconcile_mismatch_report",children:"Internal Reconciliation Reporting Table Catalog Missing or Mismatches reconcile_mismatch_report"}),"\n",(0,n.jsx)(t.p,{children:"This table would capture the discrepancies for reporting out to the operators\nabout files that are missing from ORCA S3 or have different metadata values than\nwhat is expected.\nNote that any entries with an orca_last_update after the job's\nstart_time may show as an error due to race conditions with the catalog update\nprocess, and should be displayed as such when reporting results."}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"job_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int8"})}),(0,n.jsx)(t.td,{children:"Reconcile job the report is a part of."}),(0,n.jsx)(t.td,{children:"FK constraint back to the jobs table with a many to one relationship."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"collection_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Collection ID from the ORCA Collection object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"granule_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Granule ID from the ORCA Granule object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"file_name"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"File name from the ORCA File object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"key_path"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Key path that includes the file name from the ORCA File object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"orca_etag"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Etag value from the ORCA File object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"s3_etag"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"ETag key value from S3 listing."}),(0,n.jsx)(t.td,{})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"orca_last_update"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamptz"})}),(0,n.jsx)(t.td,{children:"Last Update value from the ORCA File object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"s3_last_update"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamptz"})}),(0,n.jsx)(t.td,{children:"LastModified key value from the S3 listing."}),(0,n.jsx)(t.td,{})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"orca_size_in_bytes"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int8"})}),(0,n.jsx)(t.td,{children:"Size value from the ORCA File object the file belongs to."}),(0,n.jsx)(t.td,{children:"From Catalog."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"s3_size_in_bytes"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"int8"})}),(0,n.jsx)(t.td,{children:"Size key value from the S3 listing."}),(0,n.jsx)(t.td,{})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"discrepancy_type"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:'Type of discrepancy encountered like "value x mismatch"'}),(0,n.jsx)(t.td,{})]})]})]}),"\n",(0,n.jsx)(t.h2,{id:"open-questions-yet-to-be-answered",children:"Open Questions yet to be answered"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"What is the proper date to use when receiving a date range from Cumulus for a reconciliation report?"}),"\n",(0,n.jsx)(t.li,{children:"Should granule acquisition date be a part of the metadata?"}),"\n",(0,n.jsx)(t.li,{children:"Should optional identified attributes be added an populated now or should we start with the minimum needed?"}),"\n",(0,n.jsx)(t.li,{children:"Is GraphQL a good replacement for the current SQS - Lambda architecture?"}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"additional-artifacts-from-the-research",children:"Additional Artifacts from the Research"}),"\n",(0,n.jsx)(t.p,{children:"As part of the research, additional artifacts were created in order to help speed\nalong prototyping and design. Information and instructions on the artifacts are\nprovided below."}),"\n",(0,n.jsx)(t.h3,{id:"aqua-data-studio-erd-file",children:"Aqua Data Studio ERD File"}),"\n",(0,n.jsxs)(t.p,{children:["An entity relationship diagram (ERD) was created in ",(0,n.jsx)(t.a,{href:"https://www.aquafold.com/aquadatastudio",children:"Aqua Data Studio (ADS)"}),".\nThe ERD provides table, constraint, and reference information for the various\nobjects in the PostgreSQL database used by ORCA. The ERD diagram can be used\nfor development and scripting as well as a way to visualize object interactions.\nThe ADS ERD for ORCA can be downloaded ",(0,n.jsx)("a",{href:(0,s.A)("files/ads_orca_schema.xed"),target:"_blank",download:!0,children:"here"}),"."]}),"\n",(0,n.jsx)(t.h3,{id:"schema-install-sql-scripts",children:"Schema Install SQL Scripts"}),"\n",(0,n.jsx)(t.p,{children:"In order to quickly prototype, two SQL install scripts were created. The scripts\ninstall the ORCA inventory catalog and the internal reconciliation tables respectively.\nThe following preconditions are expected before the install scripts are run."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"The latest ORCA schema is installed in PostgreSQL (v3.x)"}),"\n",(0,n.jsx)(t.li,{children:"The user is logged into the orca database as the admin user to run the script."}),"\n"]}),"\n",(0,n.jsxs)(t.p,{children:["The ORCA inventory catalog build script is available for download ",(0,n.jsx)("a",{href:(0,s.A)("files/build_orca_inventory.sql"),target:"_blank",download:!0,children:"here"}),"."]}),"\n",(0,n.jsxs)(t.p,{children:["The ORCA internal reconciliation tables build script is available for download ",(0,n.jsx)("a",{href:(0,s.A)("files/build_orca_reconcile.sql"),target:"_blank",download:!0,children:"here"}),"."]}),"\n",(0,n.jsx)(t.h2,{id:"notes-from-orca-schema-refinement-research",children:"Notes from ORCA schema refinement research"}),"\n",(0,n.jsxs)(t.p,{children:["As part of the research, some refinements were made to the ORCA inventory catalog\nschema. This includes refinements to the ",(0,n.jsx)(t.code,{children:"granules"})," table and removal of the\n",(0,n.jsx)(t.code,{children:"provider_collection_xref"})," table and the relationship between provider and\ncollection."]}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.code,{children:"execution_id"})," has been added for helping with logging and tracing."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.code,{children:"cumulus_create_time"})," has been added for time based filtering with cumulus. The cumulus ",(0,n.jsx)(t.code,{children:"createdAt"})," time will be a consistent time source between catalogs"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.code,{children:"provider_id"})," has been added to create a relationship between granule and provider."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.code,{children:"archive_location"})," has been removed since ",(0,n.jsx)(t.code,{children:"orca_archive_location"})," already exists in the ",(0,n.jsx)(t.code,{children:"files"})," table."]}),"\n"]}),"\n",(0,n.jsx)(t.h4,{id:"refined-granule-metadata-object",children:"Refined Granule Metadata Object"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Attribute Name"}),(0,n.jsx)(t.th,{children:"Data Type"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Notable Items"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"cumulus_granule_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"granuleId that is provided by Cumulus."}),(0,n.jsx)(t.td,{children:"Must be unique per collectionId"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"provider_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"providerId that is provided by Cumulus"}),(0,n.jsx)(t.td,{children:"Ties a granule to a provider."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"collection_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"collectionId that is provided by Cumulus"}),(0,n.jsx)(t.td,{children:"Ties a granule to a collection. The collectionId and granuleId combination must be unique."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"execution_id"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"string"})}),(0,n.jsx)(t.td,{children:"Step function execution ID from AWS."}),(0,n.jsx)(t.td,{children:"Unique ID automatically generated by AWS"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"cumulus_create_time"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamp"})}),(0,n.jsx)(t.td,{children:"createdAt time provided by Cumulus when the granule was ingested."}),(0,n.jsx)(t.td,{children:"This is the Cumulus archive time used for time based comparisons."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"ingest_time"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamp"})}),(0,n.jsx)(t.td,{children:"Date and time in UTC that the data was originally ingested into ORCA"}),(0,n.jsx)(t.td,{children:"None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"last_update"}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"timestamp"})}),(0,n.jsx)(t.td,{children:"Date and time in UTC that information was updated."}),(0,n.jsx)(t.td,{children:"Potential time filter for Cumulus reconciliation."})]})]})]}),"\n",(0,n.jsx)(t.admonition,{type:"note",children:(0,n.jsxs)(t.p,{children:["It is recommended to add tags for ",(0,n.jsx)(t.code,{children:"hash"})," and ",(0,n.jsx)(t.code,{children:"hash_type"})," when the values are available to files that get copied over to S3 bucket."]})}),"\n",(0,n.jsx)(t.h3,{id:"refined-erd-file--sql-script",children:"Refined ERD File & SQL script"}),"\n",(0,n.jsxs)(t.p,{children:["The refined ADS ERD for ORCA can be downloaded ",(0,n.jsx)("a",{href:(0,s.A)("files/ads_orca_schema_refined.xed"),target:"_blank",download:!0,children:"here"}),".\nThe refined ORCA inventory catalog build script is available for download ",(0,n.jsx)("a",{href:(0,s.A)("files/build_orca_inventory_refined.sql"),target:"_blank",download:!0,children:"here"}),"."]}),"\n",(0,n.jsx)(t.h3,{id:"addressing-open-questions",children:"Addressing open questions"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["What is the proper date to use when receiving a date range from Cumulus for a reconciliation report?","\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["After discussion with the Cumulus team, we have decided to use ",(0,n.jsx)(t.code,{children:"cumulus_create_time"}),"\nwhich is passed by Cumulus ",(0,n.jsx)(t.code,{children:"createdAt"})," key in the CMA Message containing the timestamp that the granule began ingest of the granule into Cumulus.\nThis timestamp will be used to filter results for Cumulus when asking for ORCA catalog inventory information and will be captured in the Cumulus ",(0,n.jsx)(t.code,{children:"granules"})," table."]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["Should granule acquisition date be a part of the metadata?","\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"At this time, we are not going to include granule acquisition date since we cannot get it natively from Cumulus but might add it in the future."}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["Should optional identified attributes be added and populated now or should we start with the minimum needed?","\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["Added step function's ",(0,n.jsx)(t.code,{children:"execution_id"})," to the ",(0,n.jsx)(t.code,{children:"granules"})," table."]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["Is GraphQL a good replacement for the current SQS - Lambda architecture?","\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["Based on the research performed and prototype created on GraphQL, it is not currently a good replacement due to the lack of documentation which makes implementation difficult. Check ",(0,n.jsx)(t.a,{href:"https://nasa.github.io/cumulus-orca/docs/developer/research/research-graphql",children:"GraphQL research notes"})," for more information."]}),"\n"]}),"\n"]}),"\n"]})]})}function u(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(h,{...e})}):h(e)}},8453:(e,t,i)=>{i.d(t,{R:()=>r,x:()=>o});var n=i(6540);const a={},s=n.createContext(a);function r(e){const t=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),n.createElement(s.Provider,{value:t},e.children)}}}]);